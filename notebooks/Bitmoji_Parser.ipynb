{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitmoji Parser\n",
    "\n",
    "### Flow\n",
    "**For each image**:\n",
    "1. Find all of the green rectanges (HSV between (40,150,210) and (120,250,250))\n",
    "2. Save each green rectangle – with an area greater than 1000 pixels, and a height and width each greater than 40 pixels – to a new image. These represent XXX category of images and are saved with the naming convention \"\\[original name\\]-XXX_category-\\[object number\\].png\"\n",
    "3. Repeat for other colour rectangles too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import random as rng\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_fps = glob(\"../data/input/*\")\n",
    "img_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_bounding_boxes(hsv_img,\n",
    "                        colour_dict):\n",
    "    \"\"\"\n",
    "    \n",
    "        Returns an array of bounding boxes\n",
    "    \"\"\"\n",
    "    low,high = colour_dict['low_hsv'], colour_dict['high_hsv']\n",
    "    mask = cv2.inRange(hsv_img, low, high)\n",
    "    masked_img = cv2.bitwise_and(hsv_img, hsv_img, mask = mask)\n",
    "    # Converting the image to grayscale helps with the findContours function\n",
    "    masked_grey = cv2.cvtColor(masked_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Smoothing without removing edges.\n",
    "    bi_lat = cv2.bilateralFilter(masked_grey, 7, 50, 50)\n",
    "    # Adding a bit of blur and then thresholding helps reduce noise\n",
    "    blurred = cv2.blur(bi_lat, (3,3))\n",
    "    #Apply thresholding to the image\n",
    "    ret, thresholded = cv2.threshold(blurred, 1, 255, cv2.THRESH_OTSU)\n",
    "    contours, hierarchy = cv2.findContours(thresholded,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "def write_bounding_boxes(img,\n",
    "                         bounding_boxes,\n",
    "                         img_prefix = \"../data/output/[image_name]-[category]\",\n",
    "                         offset = 0,\n",
    "                         thresh = lambda x,y,w,h : h*w*1000 and w > 40 and h > 40):\n",
    "    # filter out noise based on preset threshold\n",
    "    bounding_boxes = [bb for bb in bounding_boxes if thresh(*bb)]\n",
    "    object_ids = []\n",
    "    for i,[x,y,w,h] in enumerate(bounding_boxes):\n",
    "        section = img[y:y+h, x:x+w]\n",
    "        obj_id = i+offset\n",
    "        object_ids.append(obj_id)\n",
    "        cv2.imwrite(f\"{img_prefix}-{obj_id:03d}.png\", section[:,:,::-1])\n",
    "    return bounding_boxes,object_ids\n",
    "\n",
    "\n",
    "def output_path(img_fp,colour_dict):\n",
    "    direc = \"../data/output\"\n",
    "    # Get rid of whatever is after the last period\n",
    "    img_pref = os.path.basename(img_fp).split('.')[0]\n",
    "    category = colour_dict['category']\n",
    "    return img_pref, f\"{direc}/{img_pref}_{category}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import categories\n",
    "\n",
    "series = []\n",
    "for path  in img_fps:\n",
    "    offset = 0\n",
    "    for colour in categories:\n",
    "        img_name, output_prefix = output_path(path,colour)\n",
    "        bitmoji = cv2.imread(path, 1)\n",
    "        bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_BGR2RGB)\n",
    "        hsv_bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_RGB2HSV)\n",
    "        bounding_boxes = find_bounding_boxes(hsv_bitmoji,colour)\n",
    "        bef = len(bounding_boxes)\n",
    "        bounding_boxes,object_ids = write_bounding_boxes(bitmoji,\n",
    "                                              bounding_boxes,\n",
    "                                              output_prefix,\n",
    "                                              offset)\n",
    "        offset += len(bounding_boxes)\n",
    "        for [x,y,w,h],obj_id in zip(bounding_boxes,object_ids):\n",
    "            row = [img_name, # image name\n",
    "                   colour['category'], #category\n",
    "                   obj_id,\n",
    "                   x, #X1\n",
    "                   x+w, #X2\n",
    "                   y, #Y1\n",
    "                   y+h #Y2\n",
    "                  ]\n",
    "            series.append(row)\n",
    "        if len(bounding_boxes): print(path,output_prefix,bef,'->',len(bounding_boxes))\n",
    "\n",
    "coordinate_df = pd.DataFrame(series,columns=[\"Image Name\",\n",
    "                                             \"Object Category\",\n",
    "                                             \"Object ID\",\n",
    "                                             \"X1 Coordinate\",\n",
    "                                             \"X2 Coordinate\",\n",
    "                                             \"Y1 Coordinate\",\n",
    "                                             \"Y2 Coordinate\"]).sort_values([\"Image Name\",\"Object ID\"])\n",
    "\n",
    "print(\"{} rows and {} columns\".format(*coordinate_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_df.to_csv(\"../data/coordinates.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (NOT GREAT) Parse faces"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "def get_face_colour(img,\n",
    "                    thresh = lambda x,y,w,h : h*w*1000 and w > 40 and h > 40):\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        hsv_bitmoji,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    # filter out noise based on preset threshold\n",
    "    faces = [f for f in faces if thresh(*f)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "series = []\n",
    "for path  in img_fps:\n",
    "    bitmoji = cv2.imread(path, 1)\n",
    "    bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_BGR2RGB)\n",
    "    hsv_bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "faces_df = pd.DataFrame(series,columns=[\"Image Name\",\n",
    "                                        \"Face Number\",\n",
    "                                        \"Hex Code\",\n",
    "                                        \"X1 Coordinate\",\n",
    "                                        \"X2 Coordinate\",\n",
    "                                        \"Y1 Coordinate\",\n",
    "                                        \"Y2 Coordinate\"]).sort_values([\"Image Name\",\"Object ID\"])\n",
    "\n",
    "print(\"{} rows and {} columns\".format(*coordinate_df.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bitmoji)",
   "language": "python",
   "name": "bitmoji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
