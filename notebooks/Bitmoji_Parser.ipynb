{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitmoji Parser\n",
    "\n",
    "### Flow\n",
    "**For each image**:\n",
    "1. Find all of the green rectanges (HSV between (40,150,210) and (120,250,250))\n",
    "2. Save each green rectangle – with an area greater than 1000 pixels, and a height and width each greater than 40 pixels – to a new image. These represent XXX category of images and are saved with the naming convention \"\\[original name\\]-XXX_category-\\[object number\\].png\"\n",
    "3. Repeat for other colour rectangles too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/input/user26_2195.jpg',\n",
       " '../data/input/user18_2193.jpg',\n",
       " '../data/input/user12_4668.jpg',\n",
       " '../data/input/user21_217 2.jpg',\n",
       " '../data/input/user9_3238.jpg',\n",
       " '../data/input/user9_4519.jpg',\n",
       " '../data/input/user11_106.jpg',\n",
       " '../data/input/user9_4520.jpg',\n",
       " '../data/input/user10_4547 2.jpg',\n",
       " '../data/input/user21_217.jpg',\n",
       " '../data/input/user17_1570.jpg',\n",
       " '../data/input/user16_2800.jpg',\n",
       " '../data/input/user16_2800 2.jpg',\n",
       " '../data/input/user10_4547.jpg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import random as rng\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_fps = glob(\"../data/input/*\")\n",
    "img_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_bounding_boxes(hsv_img,\n",
    "                        colour_dict):\n",
    "    \"\"\"\n",
    "    \n",
    "        Returns an array of bounding boxes\n",
    "    \"\"\"\n",
    "    low,high = colour_dict['low_hsv'], colour_dict['high_hsv']\n",
    "    mask = cv2.inRange(hsv_img, low, high)\n",
    "    masked_img = cv2.bitwise_and(hsv_img, hsv_img, mask = mask)\n",
    "    # Converting the image to grayscale helps with the findContours function\n",
    "    masked_grey = cv2.cvtColor(masked_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Smoothing without removing edges.\n",
    "    bi_lat = cv2.bilateralFilter(masked_grey, 7, 50, 50)\n",
    "    # Adding a bit of blur and then thresholding helps reduce noise\n",
    "    blurred = cv2.blur(bi_lat, (3,3))\n",
    "    #Apply thresholding to the image\n",
    "    ret, thresholded = cv2.threshold(blurred, 1, 255, cv2.THRESH_OTSU)\n",
    "    contours, hierarchy = cv2.findContours(thresholded,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "def write_bounding_boxes(img,\n",
    "                         bounding_boxes,\n",
    "                         img_prefix = \"../data/output/[image_name]-[category]\",\n",
    "                         offset = 0,\n",
    "                         thresh = lambda x,y,w,h : h*w*1000 and w > 40 and h > 40):\n",
    "    # filter out noise based on preset threshold\n",
    "    bounding_boxes = [bb for bb in bounding_boxes if thresh(*bb)]\n",
    "    object_ids = []\n",
    "    for i,[x,y,w,h] in enumerate(bounding_boxes):\n",
    "        section = img[y:y+h, x:x+w]\n",
    "        obj_id = i+offset\n",
    "        object_ids.append(obj_id)\n",
    "        cv2.imwrite(f\"{img_prefix}-{obj_id:03d}.png\", section[:,:,::-1])\n",
    "    return bounding_boxes,object_ids\n",
    "\n",
    "\n",
    "def output_path(img_fp,colour_dict):\n",
    "    direc = \"../data/output/objects\"\n",
    "    # Get rid of whatever is after the last period\n",
    "    img_pref = os.path.basename(img_fp).split('.')[0]\n",
    "    category = colour_dict['category']\n",
    "    return img_pref, f\"{direc}/{img_pref}_{category}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/user26_2195.jpg ../data/output/objects/user26_2195_02_wall_hangings 1 -> 1\n",
      "../data/input/user18_2193.jpg ../data/output/objects/user18_2193_02_wall_hangings 21 -> 6\n",
      "../data/input/user12_4668.jpg ../data/output/objects/user12_4668_02_wall_hangings 3 -> 3\n",
      "../data/input/user12_4668.jpg ../data/output/objects/user12_4668_03_objects 1 -> 1\n",
      "../data/input/user21_217 2.jpg ../data/output/objects/user21_217 2_01_books 6 -> 3\n",
      "../data/input/user21_217 2.jpg ../data/output/objects/user21_217 2_02_wall_hangings 3 -> 2\n",
      "../data/input/user21_217 2.jpg ../data/output/objects/user21_217 2_03_objects 2 -> 2\n",
      "../data/input/user9_3238.jpg ../data/output/objects/user9_3238_01_books 3 -> 3\n",
      "../data/input/user9_3238.jpg ../data/output/objects/user9_3238_02_wall_hangings 4 -> 2\n",
      "../data/input/user9_3238.jpg ../data/output/objects/user9_3238_03_objects 3 -> 3\n",
      "../data/input/user9_4519.jpg ../data/output/objects/user9_4519_01_books 11 -> 4\n",
      "../data/input/user9_4519.jpg ../data/output/objects/user9_4519_02_wall_hangings 22 -> 2\n",
      "../data/input/user9_4519.jpg ../data/output/objects/user9_4519_03_objects 3 -> 2\n",
      "../data/input/user11_106.jpg ../data/output/objects/user11_106_01_books 30 -> 13\n",
      "../data/input/user11_106.jpg ../data/output/objects/user11_106_02_wall_hangings 4 -> 2\n",
      "../data/input/user11_106.jpg ../data/output/objects/user11_106_03_objects 5 -> 5\n",
      "../data/input/user9_4520.jpg ../data/output/objects/user9_4520_02_wall_hangings 27 -> 3\n",
      "../data/input/user9_4520.jpg ../data/output/objects/user9_4520_03_objects 7 -> 1\n",
      "../data/input/user10_4547 2.jpg ../data/output/objects/user10_4547 2_01_books 11 -> 1\n",
      "../data/input/user21_217.jpg ../data/output/objects/user21_217_01_books 47 -> 14\n",
      "../data/input/user21_217.jpg ../data/output/objects/user21_217_02_wall_hangings 7 -> 5\n",
      "../data/input/user21_217.jpg ../data/output/objects/user21_217_03_objects 2 -> 2\n",
      "../data/input/user17_1570.jpg ../data/output/objects/user17_1570_03_objects 3 -> 3\n",
      "../data/input/user16_2800.jpg ../data/output/objects/user16_2800_02_wall_hangings 3 -> 1\n",
      "../data/input/user16_2800 2.jpg ../data/output/objects/user16_2800 2_02_wall_hangings 51 -> 8\n",
      "../data/input/user16_2800 2.jpg ../data/output/objects/user16_2800 2_03_objects 13 -> 12\n",
      "../data/input/user10_4547.jpg ../data/output/objects/user10_4547_01_books 20 -> 3\n",
      "../data/input/user10_4547.jpg ../data/output/objects/user10_4547_02_wall_hangings 58 -> 4\n",
      "111 rows and 7 columns\n"
     ]
    }
   ],
   "source": [
    "from utils import categories\n",
    "\n",
    "series = []\n",
    "for path  in img_fps:\n",
    "    offset = 0\n",
    "    for colour in categories:\n",
    "        img_name, output_prefix = output_path(path,colour)\n",
    "        bitmoji = cv2.imread(path, 1)\n",
    "        bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_BGR2RGB)\n",
    "        hsv_bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_RGB2HSV)\n",
    "        bounding_boxes = find_bounding_boxes(hsv_bitmoji,colour)\n",
    "        bef = len(bounding_boxes)\n",
    "        bounding_boxes,object_ids = write_bounding_boxes(bitmoji,\n",
    "                                              bounding_boxes,\n",
    "                                              output_prefix,\n",
    "                                              offset)\n",
    "        offset += len(bounding_boxes)\n",
    "        for [x,y,w,h],obj_id in zip(bounding_boxes,object_ids):\n",
    "            row = [img_name, # image name\n",
    "                   colour['category'], #category\n",
    "                   obj_id,\n",
    "                   x, #X1\n",
    "                   x+w, #X2\n",
    "                   y, #Y1\n",
    "                   y+h #Y2\n",
    "                  ]\n",
    "            series.append(row)\n",
    "        if len(bounding_boxes): print(path,output_prefix,bef,'->',len(bounding_boxes))\n",
    "\n",
    "coordinate_df = pd.DataFrame(series,columns=[\"Image Name\",\n",
    "                                             \"Object Category\",\n",
    "                                             \"Object ID\",\n",
    "                                             \"X1 Coordinate\",\n",
    "                                             \"X2 Coordinate\",\n",
    "                                             \"Y1 Coordinate\",\n",
    "                                             \"Y2 Coordinate\"]).sort_values([\"Image Name\",\"Object ID\"])\n",
    "\n",
    "print(\"{} rows and {} columns\".format(*coordinate_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_df.to_csv(\"../data/coordinates.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bitmoji)",
   "language": "python",
   "name": "bitmoji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
