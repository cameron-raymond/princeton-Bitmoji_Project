{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitmoji Parser\n",
    "\n",
    "### Flow\n",
    "**For each image**:\n",
    "1. Find all of the green rectanges (HSV between (40,150,210) and (120,250,250))\n",
    "2. Save each green rectangle – with an area greater than 1000 pixels, and a height and width each greater than 40 pixels – to a new image. These represent XXX category of images and are saved with the naming convention \"\\[original name\\]-XXX_category-\\[object number\\].png\"\n",
    "3. Repeat for other colour rectangles too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/input/user106_341.jpg',\n",
       " '../data/input/user106_346.jpg',\n",
       " '../data/input/user147_2362.jpg',\n",
       " '../data/input/test1.jpg',\n",
       " '../data/input/user99_310.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import random as rng\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_fps = glob(\"../data/input/*\")\n",
    "img_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_bounding_boxes(hsv_img,\n",
    "                        colour_dict):\n",
    "    \"\"\"\n",
    "    \n",
    "        Returns an array of bounding boxes\n",
    "    \"\"\"\n",
    "    low,high = colour_dict['low_hsv'], colour_dict['high_hsv']\n",
    "    mask = cv2.inRange(hsv_img, low, high)\n",
    "    masked_img = cv2.bitwise_and(hsv_img, hsv_img, mask = mask)\n",
    "    # Converting the image to grayscale helps with the findContours function\n",
    "    masked_grey = cv2.cvtColor(masked_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Adding a bit of blur and then thresholding helps reduce noise\n",
    "    blurred = cv2.blur(masked_grey, (3,3))\n",
    "    #Apply thresholding to the image\n",
    "    ret, thresholded = cv2.threshold(blurred, 1, 255, cv2.THRESH_OTSU)\n",
    "    contours, hierarchy = cv2.findContours(thresholded,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "def write_bounding_boxes(img,\n",
    "                         bounding_boxes,\n",
    "                         img_prefix = \"../data/output/[image_name]-[category]\",\n",
    "                         thresh = lambda x,y,w,h : h*w*1000 and w > 40 and h > 40):\n",
    "    # filter out noise based on preset threshold\n",
    "    bounding_boxes = [bb for bb in bounding_boxes if thresh(*bb)]\n",
    "    for i,[x,y,w,h] in enumerate(bounding_boxes):\n",
    "        section = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(f\"{img_prefix}-{i}.png\", section[:,:,::-1])\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "def output_path(img_fp,colour_dict):\n",
    "    direc = \"../data/output\"\n",
    "    # Get rid of whatever is after the last period\n",
    "    img_pref = os.path.basename(img_fp).split('.')[0]\n",
    "    category = colour_dict['category']\n",
    "    return f\"{direc}/{img_pref}-{category}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/user106_341.jpg ../data/output/user106_341-poster 4 -> 3\n",
      "../data/input/user106_346.jpg ../data/output/user106_346-poster 8 -> 7\n",
      "../data/input/user147_2362.jpg ../data/output/user147_2362-poster 32 -> 11\n",
      "../data/input/user147_2362.jpg ../data/output/user147_2362-device 46 -> 1\n",
      "../data/input/test1.jpg ../data/output/test1-poster 15 -> 4\n",
      "../data/input/test1.jpg ../data/output/test1-device 27 -> 2\n",
      "../data/input/user99_310.jpg ../data/output/user99_310-device 14 -> 3\n"
     ]
    }
   ],
   "source": [
    "from utils import categories\n",
    "\n",
    "for path  in img_fps:\n",
    "    for colour in categories:\n",
    "        output_prefix = output_path(path,colour)\n",
    "        bitmoji = cv2.imread(path, 1)\n",
    "        bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_BGR2RGB)\n",
    "        hsv_bitmoji = cv2.cvtColor(bitmoji, cv2.COLOR_RGB2HSV)\n",
    "        bounding_boxes = find_bounding_boxes(hsv_bitmoji,colour)\n",
    "        bef = len(bounding_boxes)\n",
    "        bounding_boxes = write_bounding_boxes(bitmoji,\n",
    "                                              bounding_boxes,\n",
    "                                              output_prefix)\n",
    "        if len(bounding_boxes): print(path,output_prefix,bef,'->',len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bitmoji)",
   "language": "python",
   "name": "bitmoji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
